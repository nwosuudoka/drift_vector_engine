# **Global Master Plan: Drift-Aware Vector Engine**

#### **Section 1: Storage Layer (Level 1)**

**Status:** âœ… **Complete.** The bedrock is solid.

- âœ… **Custom `.drift` File Format:** `SegmentWriter`/`SegmentReader` with Footer/Index.

- âœ… **Disk Manager:** Async I/O with seek support.

- âœ… **Block Alignment:** `PageBlock` for 4KB alignment.

- âœ… **Compression:**

  - SQ8 Quantizer (1-99% clipping).
  - ALP/ALP_RD for Floats.
  - FastLanes for Integers.

- âœ… **Bloom Filters:** Integrated into footer for O(1) negative lookups.

#### **Section 2: Core Indexing Logic (Level 1)**

**Status:** âœ… **Complete.** The engine logic works.

- âœ… **Bucket Structure:** SoA layout with `AlignedBytes`.

- âœ… **ADC Scanning:** SIMD-optimized `scan_adc`.

- âœ… **Maintenance Primitives:**
  - Split (Neighbor Stealing).
  - Merge (Scatter Merge).
  - Urgency Calculation ("Hot Zombie" formula).

#### **Section 3: Memory Structure (Level 0)**

**Status:** âœ… **Complete.** The ingest path is fully operational.

- âœ… **HNSW Graph:** Thread-safe MemTable for hot data.

- âœ… **Hybrid Search:** Merges L0 (Graph) and L1 (Disk) results seamlessly.

- âœ… **Flushing Logic:** `Janitor` rotates MemTable, trains Quantizer (cold start), and flushes to Disk.

- âœ… **Write-Ahead Log (WAL):** Durability guaranteed. Crashes recover data from WAL before hydration.

#### **Section 4: Execution Engine**

**Status:** âœ… **Complete.**

- âœ… **Epoch-Based Reclamation:** `crossbeam-epoch` manages lock-free memory safety.

- âœ… **Probabilistic Stopping:** Saturating Density scoring implemented.

- âœ… **Concurrency:** Lock-free reads on the hot path.

#### **Section 5: Server & API**

**Status:** âœ… **Complete.** We have a working server.

- âœ… **Persistence Manager:** Handles Hydration (Disk -> RAM) and Flushing (RAM -> Disk).

- âœ… **gRPC Interface:** `DriftService` implements `Insert` and `Search` via Protobuf.

- âœ… **Multi-Tenancy:** `CollectionManager` creates isolated indices on-the-fly (`/data/users`, `/data/products`).

- âœ… **Background Workers:** `Janitor` runs per-collection to manage lifecycle.

---

### **Where We Are: The "Golden Path" is Live**

We have built a system that:

1. **Accepts Data** via gRPC.
2. **Writes safely** to a WAL.
3. **Serves immediately** from RAM (HNSW).
4. **Autonomously flushes** to compressed Disk Segments.
5. **Recovers perfectly** from crashes (Hydration + WAL Replay).
6. **Isolates Tenants** via Collections.

### **The Final Frontier: Distributed Routing**

The only item remaining from the original plan is the **Request Router**. Currently, `Drift` is a "Scale-Up" database (single node, many cores). To become "Scale-Out" (infinite storage), we need to shard data across multiple nodes.

**Updated Todo List:**

Section 6: Scaling & Optimization (New)

Status: ðŸš§ In Progress.

- â¬œ **Global ID Index**: Integrate BitStore (Disk Hash Table) to map VectorID -> BucketID for O(1) deletes/updates.
- â¬œ **Distributed Consensus**: Use a lightweight consensus (or consistent hashing) to map Collection -> Node.
- â¬œ **Request Router**: Forward gRPC requests to the correct node/shard.
- â¬œ **CLI Tooling**: A proper command-line interface (drift-cli) to admin the cluster.
